{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import stats\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import zscore\nfrom scipy.spatial import distance\nfrom scipy.cluster.hierarchy import linkage, dendrogram, fcluster\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.decomposition import PCA",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df=pd.read_csv(\"marketing.csv\")\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## lets check the basic information of the dataset\ndf.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## lets check missing values in the dataset\ndf.isnull().sum()/len(df)*100",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Filling the missing value in the income my mean\ndf['Income'] = df['Income'].fillna(df['Income'].mean())\n\n## Lets recheck the missing values\ndf.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Check duplicated records in the dataset\nlen(df[df.duplicated()])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## dropping redundant columns\ndf = df.drop(columns=['ID','Dt_Customer'],axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Checking number of unique categories present in the \"Marital_Status\"\ndf['Marital_Status'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df['Marital_Status'] = df['Marital_Status'].replace(['Married', 'Together'],'relationship')\ndf['Marital_Status'] = df['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd'],'Single')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## recheck after grouping the categories.\ndf['Marital_Status'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df['Total_Expenses'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df['NumTotalPurchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumDealsPurchases']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df['Kids'] = df['Kidhome'] + df['Teenhome']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df['TotalAcceptedCmp'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + df['AcceptedCmp5'] + df['Response']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": " Dropping the columns, since we have grouped them\n\ncol_del = [\"AcceptedCmp1\" , \"AcceptedCmp2\", \"AcceptedCmp3\" , \"AcceptedCmp4\",\"AcceptedCmp5\", \"Response\",\"NumWebVisitsMonth\", \"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\",\"NumDealsPurchases\" , \"Kidhome\", \"Teenhome\",\"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\"]\ndf=df.drop(columns=col_del,axis=1)\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Adding a column \"Age\" in the dataframe\ndf['Age'] = 2022 - df[\"Year_Birth\"]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.drop('Year_Birth',axis=1,inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.head(2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dfc = df.copy()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Label Encoding\ncate=['Education', 'Marital_Status']\nlbl_encode = LabelEncoder()\nfor i in cate:\n    df[i]=df[[i]].apply(lbl_encode.fit_transform)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Standardization\ndf1 = df.copy()\nscaled_features = StandardScaler().fit_transform(df1.values)\nscaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "scaled_features_df.head(3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## step1: Calculate the covariance matrix.\ncov_matrix = np.cov(scaled_features.T)\ncov_matrix",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## step2: Calculate the eigen values and eigen vectors.\neig_vals, eig_vectors = np.linalg.eig(cov_matrix)\nprint('eigein vals:','\\n',eig_vals)\nprint('\\n')\nprint('eigein vectors','\\n',eig_vectors)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## step3: Scree plot.\ntotal = sum(eig_vals)\nvar_exp = [(i/total)*100 for i in sorted(eig_vals,reverse=True)]\ncum_var_exp = np.cumsum(var_exp)\nprint('Explained Variance: ',var_exp)\nprint('Cummulative Variance Explained: ',cum_var_exp)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Scree plot.\nplt.bar(range(10),var_exp,align='center',color='lightgreen',edgecolor='black',label='Explained Variance')\nplt.step(range(10),cum_var_exp,where='mid',color='red',label='Cummulative Explained Variance')\nplt.xlabel('Principal Components')\nplt.ylabel('Explianed Variance ratio')\nplt.title('Scree Plot')\nplt.legend(loc='best')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Using the dimensions obtainted from the PCA to apply clustering.(i.e, 8)\npca = PCA(n_components=8)\n\npca_df = pd.DataFrame(pca.fit_transform(scaled_features_df),columns=['PC1','PC2','PC3','PC4','PC5','PC6', 'PC7', 'PC8'])\npca_df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## finding optimal K value by KMeans clustering using Elbow plot.\ncluster_errors = []\ncluster_range = range(2,15)\nfor num_clusters in cluster_range:\n    clusters = KMeans(num_clusters,random_state=100)\n    clusters.fit(pca_df)\n    cluster_errors.append(clusters.inertia_)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## creataing a dataframe of number of clusters and cluster errors.\ncluster_df = pd.DataFrame({'num_clusters':cluster_range,'cluster_errors':cluster_errors})\n\n## Elbow plot.\nplt.figure(figsize=[15,5])\nplt.plot(cluster_df['num_clusters'],cluster_df['cluster_errors'],marker='o',color='b')\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Applying KMeans clustering for the optimal number of clusters obtained above.\nkmeans = KMeans(n_clusters=3, random_state=100)\nkmeans.fit(pca_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## creating a dataframe of the labels.\nlabel = pd.DataFrame(kmeans.labels_,columns=['Label'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## joining the label dataframe to the pca_df dataframe.\nkmeans_df = pca_df.join(label)\nkmeans_df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "kmeans_df['Label'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## visualizing the clusters formed \nsns.scatterplot(kmeans_df['PC1'],kmeans_df['PC2'],hue='Label',data=kmeans_df)\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=[18,5])\nmerg = linkage(scaled_features, method='ward')\ndendrogram(merg, leaf_rotation=90,)\nplt.xlabel('Datapoints')\nplt.ylabel('Euclidean distance')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import silhouette_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "for i in range(2,15):\n    hier = AgglomerativeClustering(n_clusters=i)\n    hier = hier.fit(scaled_features_df)\n    labels = hier.fit_predict(scaled_features_df)\n    print(i,silhouette_score(scaled_features_df,labels))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Building hierarchical clustering model using the optimal clusters as 3 using original data\nhie_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean',\n                                     linkage='ward')\nhie_cluster_model = hie_cluster.fit(scaled_features_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Creating a dataframe of the labels\ndf_label1 = pd.DataFrame(hie_cluster_model.labels_,columns=['Labels'])\ndf_label1.head(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## joining the label dataframe with unscaled initial cleaned dataframe.(dfc)\n\ndf_hier = dfc.join(df_label1)\ndf_hier.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.barplot(df_hier['Labels'],df_hier['Total_Expenses'])\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.barplot(df_hier['Labels'],df_hier['Income'])\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.countplot(df_hier['Marital_Status'],hue='Labels',data=df_hier)\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "sns.barplot(df_hier['Labels'],df_hier['NumTotalPurchases'])\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}